{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuman\\anaconda3\\envs\\pytorch_v1\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib as plt\n",
    "from data import data_preprocess, data_trans\n",
    "from modelbase import STA_LSTM as Net\n",
    "# from modelbase import SA_LSTM as Net\n",
    "# from modelbase import TA_LSTM as Net\n",
    "# from modelbase import LSTM as Net\n",
    "# from modelbase import FCN as Net\n",
    "# from modelbase import SVM as Net\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train(verbose = False):\n",
    "\n",
    "    net.train()\n",
    "    loss_list = []\n",
    "    alphas_list, betas_list = [],[]\n",
    "    \n",
    "    for i,data in enumerate(train_dataloader):\n",
    "       \n",
    "        inputs = data['inputs']\n",
    "        groundtruths = data['groundtruths']     \n",
    "        \n",
    "        if USE_GPU:\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            groundtruths = Variable(groundtruths).cuda()\n",
    "            \n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            groundtruths = Variable(groundtruths)\n",
    "        \n",
    "        #将参数的grad值初始化为0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #获得网络输出结果\n",
    "        out, alphas, betas = net(inputs)\n",
    "        \n",
    "        alphas_list.append(alphas)\n",
    "        betas_list.append(betas)\n",
    "        \n",
    "        #根据真值计算损失函数的值\n",
    "        loss = loss_criterion(out,groundtruths)\n",
    "\n",
    "        #通过优化器优化网络\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "    \n",
    "    return loss_list, alphas_list, betas_list\n",
    "\n",
    "def vali(verbose = False):\n",
    "\n",
    "    net.eval()\n",
    "    loss_list = []\n",
    "\n",
    "    for i,data in enumerate(train_dataloader):\n",
    "       \n",
    "        inputs = data['inputs']\n",
    "        groundtruths = data['groundtruths']     \n",
    "        \n",
    "        if USE_GPU:\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            groundtruths = Variable(groundtruths).cuda()\n",
    "            \n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            groundtruths = Variable(groundtruths)\n",
    "\n",
    "        #获得网络输出结果\n",
    "        out, _, _ = net(inputs)\n",
    "        \n",
    "        #根据真值计算损失函数的值\n",
    "        loss = loss_criterion(out,groundtruths)\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "    return loss_list\n",
    "\n",
    "def test():\n",
    "    \n",
    "    error = 0.0\n",
    "    predictions = []\n",
    "    test_groundtruths = []\n",
    "\n",
    "    # 告诉网络进行测试，不再是训练模式\n",
    "    net.eval() \n",
    "\n",
    "    for i,data in enumerate(test_dataloader):\n",
    "\n",
    "        inputs = data['inputs']\n",
    "        groundtruths = data['groundtruths']     \n",
    "        \n",
    "        if USE_GPU:\n",
    "\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            groundtruths = Variable(groundtruths).cuda()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            inputs = Variable(inputs)\n",
    "            groundtruths = Variable(groundtruths)\n",
    "\n",
    "        out, _, _ = net(inputs)\n",
    "        error += (error_criterion(out,groundtruths).item()*groundtruths.size(0))\n",
    "\n",
    "        if USE_GPU:\n",
    "            predictions.extend(out.cpu().data.numpy().tolist())\n",
    "            test_groundtruths.extend(groundtruths.cpu().data.numpy().tolist())\n",
    "            \n",
    "        else:\n",
    "            predictions.extend(out.data.numpy().tolist())\n",
    "            test_groundtruths.extend(groundtruths.data.numpy().tolist())\n",
    "      \n",
    "    average_error = np.sqrt(error/len(test_data_trans))\n",
    "    \n",
    "    return np.array(predictions).reshape((len(predictions))),np.array(test_groundtruths).reshape((len(test_groundtruths))),average_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert from each station's file to sample_aq_t+1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blh</th>\n",
       "      <th>d2m</th>\n",
       "      <th>sp</th>\n",
       "      <th>t2m</th>\n",
       "      <th>smoke</th>\n",
       "      <th>fire</th>\n",
       "      <th>060370016_PM2.5</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_spd</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>holiday</th>\n",
       "      <th>060371103</th>\n",
       "      <th>060590007</th>\n",
       "      <th>060658005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26305</th>\n",
       "      <td>258.807146</td>\n",
       "      <td>279.257257</td>\n",
       "      <td>90259.986231</td>\n",
       "      <td>280.289850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>219.634078</td>\n",
       "      <td>2.367715</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26306</th>\n",
       "      <td>291.375577</td>\n",
       "      <td>278.787604</td>\n",
       "      <td>90275.489187</td>\n",
       "      <td>279.702898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>240.017901</td>\n",
       "      <td>2.599394</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26307</th>\n",
       "      <td>318.933480</td>\n",
       "      <td>278.112687</td>\n",
       "      <td>90290.992142</td>\n",
       "      <td>278.476318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>262.584690</td>\n",
       "      <td>2.010053</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26308</th>\n",
       "      <td>152.044361</td>\n",
       "      <td>277.936427</td>\n",
       "      <td>90304.356759</td>\n",
       "      <td>278.337105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>241.357016</td>\n",
       "      <td>0.934233</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26309</th>\n",
       "      <td>95.097786</td>\n",
       "      <td>277.556020</td>\n",
       "      <td>90282.438788</td>\n",
       "      <td>277.920720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>175.670195</td>\n",
       "      <td>0.204549</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              blh         d2m            sp         t2m  smoke  fire  \\\n",
       "26305  258.807146  279.257257  90259.986231  280.289850    0.0   0.0   \n",
       "26306  291.375577  278.787604  90275.489187  279.702898    0.0   0.0   \n",
       "26307  318.933480  278.112687  90290.992142  278.476318    0.0   0.0   \n",
       "26308  152.044361  277.936427  90304.356759  278.337105    0.0   0.0   \n",
       "26309   95.097786  277.556020  90282.438788  277.920720    0.0   0.0   \n",
       "\n",
       "       060370016_PM2.5    wind_dir  wind_spd  day_of_year  hour  day_of_week  \\\n",
       "26305              1.4  219.634078  2.367715            1     1            6   \n",
       "26306              3.8  240.017901  2.599394            1     2            6   \n",
       "26307             19.9  262.584690  2.010053            1     3            6   \n",
       "26308             22.5  241.357016  0.934233            1     4            6   \n",
       "26309             35.3  175.670195  0.204549            1     5            6   \n",
       "\n",
       "       quarter  holiday  060371103  060590007  060658005  \n",
       "26305        1    False        4.0        3.3        3.8  \n",
       "26306        1    False        3.0        4.5        5.0  \n",
       "26307        1    False        2.0        6.9        8.2  \n",
       "26308        1    False        3.0       10.3        8.2  \n",
       "26309        1    False        8.0       24.0        5.8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 12   # 时间序列长度，即为回溯期\n",
    "prediction_horizon = 2\n",
    "\n",
    "'''****************************AQ data preparation*******************************'''\n",
    "sensors = pd.read_csv('D:/Code/Code-AQ/airnow/processed_airnow/sensors_ca_preprocessed.csv', index_col=False)\n",
    "\n",
    "fpath = \"D:/Code/Code-Smoke-AQ/processed_data/airnow_smoke_fire/\"\n",
    "PM25_files = [fpath+f for f in os.listdir(fpath) if f.endswith('.csv')]\n",
    "\n",
    "# larger la\n",
    "PM25_files = [fpath+f for f in os.listdir(fpath) if f.startswith('06037') or f.startswith('06059') or f.startswith('06065') or f.startswith('06111')]\n",
    "PM25_files\n",
    "\n",
    "fname = PM25_files[0]\n",
    "data = pd.read_csv(fname)\n",
    "data = data[26305:52585] # 2017-2019\n",
    "data = data.drop(columns=['datetime','u10','v10'])\n",
    "\n",
    "cols = list(data.columns[:])\n",
    "cols_PM25 = [col for col in cols if 'PM2.5' in col]\n",
    "data[cols_PM25] = data[cols_PM25].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "############################# include nearby sensors into data\n",
    "sensor = fname.split('/')[-1].split('.')[0]\n",
    "sensor_lon = sensors.loc[sensors['AQSID'] == int(sensor),'longitude'].values[0]\n",
    "sensor_lat = sensors.loc[sensors['AQSID'] == int(sensor),'latitude'].values[0]\n",
    "# print(sensor, sensor_lon, sensor_lat)\n",
    "\n",
    "distances = {}\n",
    "for file in PM25_files:\n",
    "    if file != fname:\n",
    "        # print(file, fname)\n",
    "        sensor_near = file.split('/')[-1].split('.')[0]\n",
    "        sensor_lon_near = sensors.loc[sensors['AQSID'] == int(sensor_near),'longitude'].values[0]\n",
    "        sensor_lat_near = sensors.loc[sensors['AQSID'] == int(sensor_near),'latitude'].values[0]\n",
    "        # print(sensor_near, sensor_lon_near, sensor_lat_near)\n",
    "        dist = sqrt( (sensor_lon_near - sensor_lon)**2 + (sensor_lat_near - sensor_lat)**2 )\n",
    "        if dist <= 0.4:\n",
    "            distances[file] = dist\n",
    "\n",
    "# print(distances)\n",
    "\n",
    "for file in distances.keys():\n",
    "    temp = pd.read_csv(file)\n",
    "    temp = temp[26305:52585] # 2017-2019\n",
    "    temp = temp[[[col for col in temp.columns if 'PM2.5' in col][0]]]\n",
    "    temp.columns = [file.split('/')[-1].split('.')[0]]\n",
    "    temp = temp.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    data[file.split('/')[-1].split('.')[0]] = temp\n",
    "\n",
    "cols = list(data.columns[:])\n",
    "cols_PM25 = [col for col in cols if 'PM2.5' in col]\n",
    "\n",
    "############################# end include nearby sensors into data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# t0_v0, t0_v1, ..., t1_v0, t1_v1, .... , th_v0, th_v1, ...., t+h+1_target \n",
    "data_ = np.zeros((len(data), len(cols)*SEQUENCE_LENGTH + 1)) \n",
    "\n",
    "for i in range(SEQUENCE_LENGTH):\n",
    "    data_[:, len(cols)*i:len(cols)*(i+1)] = data.shift(-i-1).fillna(method='bfill')\n",
    "    \n",
    "data_[:,-1] = data[cols_PM25].shift(-SEQUENCE_LENGTH - prediction_horizon).fillna(method='bfill').values.reshape(1,-1)\n",
    "\n",
    "data_ = data_[:len(data)-SEQUENCE_LENGTH-prediction_horizon]\n",
    "\n",
    "# Add all time points in the columns\n",
    "column_names = []\n",
    "for i in range(SEQUENCE_LENGTH):\n",
    "    for var in cols:\n",
    "        column_names.append(var+'_t'+str(i))\n",
    "column_names.append('t+'+str(prediction_horizon))\n",
    "\n",
    "df = pd.DataFrame(data_, columns=column_names)\n",
    "\n",
    "savefp = './data/dataset/'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.csv'\n",
    "df.to_csv(savefp,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''****************************initialization*******************************''' \n",
    "IN_DIM =  len(cols)*SEQUENCE_LENGTH    # 因变量 number*SEQUENCE_LENGTH\n",
    "\n",
    "LSTM_IN_DIM = len(cols)     # LSTM的input大小,等于总的变量长度/时间序列长度\n",
    "LSTM_HIDDEN_DIM = 300  # LSTM隐状态的大小\n",
    "\n",
    "OUT_DIM = 1            # 输出大小\n",
    "\n",
    "LEARNING_RATE = 0.05 # learning rate\n",
    "WEIGHT_DECAY = 1e-6    # L2惩罚项\n",
    "\n",
    "BATCH_SIZE = 200        # batch size\n",
    "\n",
    "EPOCHES = 180    # epoch大小\n",
    "\n",
    "TRAIN_PER = 0.80 # 训练集占比\n",
    "VALI_PER = 0.0 # 验证集占比\n",
    "\n",
    "# 判断是否采用GPU加速\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "# USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''****************************data prepration*******************************''' \n",
    "# 准备好训练和测试数据\n",
    "dp = data_preprocess(file_path = savefp, train_per = TRAIN_PER, vali_per = VALI_PER, in_dim = IN_DIM)\n",
    "\n",
    "raw_data = dp.load_data()\n",
    "# print('数据导入完成')\n",
    "\n",
    "(train_data,train_groundtruth),(vali_data,vali_groundtruth),(test_data,test_groundtruth) = dp.split_data(raw_data = raw_data, _type = 'linear')\n",
    "# print('数据分割完成')\n",
    "\n",
    "# 设置对数据进行的转换方式，transform.compose的作用是将多个transform组合到一起进行使用\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=(0,0,0),std=(1,1,1))])\n",
    "\n",
    "# print('数据转换为tensor')\n",
    "\n",
    "# data_trans返回的值是一个字典，内部包含数据和真值{'inputs':inputs,'groundtruth':groundtruths}\n",
    "\n",
    "# 准备训练集\n",
    "train_data_trans = data_trans(train_data,train_groundtruth,transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_trans,\n",
    "                                           batch_size =BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers = 4)\n",
    "# print('训练集准备完毕')\n",
    "\n",
    "# 准备val集\n",
    "vali_data_trans = data_trans(vali_data, vali_groundtruth, transform)\n",
    "\n",
    "vali_dataloader = torch.utils.data.DataLoader(vali_data_trans,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = False,\n",
    "                                           num_workers = 4)\n",
    "\n",
    "\n",
    "# 准备测试集\n",
    "test_data_trans = data_trans(test_data, test_groundtruth,transform)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_trans,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = False,\n",
    "                                           num_workers = 4)\n",
    "# print('测试集准备完毕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26266, 205)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.91375577e+02,  2.78787604e+02,  9.02754892e+04, ...,\n",
       "         9.30000000e+00,  3.15000000e+01, -1.60000000e+00],\n",
       "       [ 3.18933480e+02,  2.78112687e+02,  9.02909921e+04, ...,\n",
       "         1.24000000e+01,  3.55000000e+01, -1.00000000e-01],\n",
       "       [ 1.52044361e+02,  2.77936427e+02,  9.03043568e+04, ...,\n",
       "         1.76000000e+01,  3.17000000e+01,  7.90000000e+00],\n",
       "       ...,\n",
       "       [ 1.08375126e+02,  2.70912788e+02,  9.08184005e+04, ...,\n",
       "         8.00000000e-01,  2.10000000e+00,  7.30000000e+00],\n",
       "       [ 2.70219929e+02,  2.70924112e+02,  9.08005738e+04, ...,\n",
       "         1.00000000e+00,  1.10000000e+00,  4.80000000e+00],\n",
       "       [ 6.62851362e+01,  2.69857382e+02,  9.08283624e+04, ...,\n",
       "         1.50000000e+00,  8.00000000e-01,  5.60000000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21012, 204)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21012, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_groundtruth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5254, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_groundtruth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9138e+02, 2.7879e+02, 9.0275e+04, 2.7970e+02, 0.0000e+00, 0.0000e+00,\n",
       "        3.8000e+00, 2.4002e+02, 2.5994e+00, 1.0000e+00, 2.0000e+00, 6.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 3.0000e+00, 4.5000e+00, 5.0000e+00, 3.1893e+02,\n",
       "        2.7811e+02, 9.0291e+04, 2.7848e+02, 0.0000e+00, 0.0000e+00, 1.9900e+01,\n",
       "        2.6258e+02, 2.0101e+00, 1.0000e+00, 3.0000e+00, 6.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 2.0000e+00, 6.9000e+00, 8.2000e+00, 1.5204e+02, 2.7794e+02,\n",
       "        9.0304e+04, 2.7834e+02, 0.0000e+00, 0.0000e+00, 2.2500e+01, 2.4136e+02,\n",
       "        9.3423e-01, 1.0000e+00, 4.0000e+00, 6.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        3.0000e+00, 1.0300e+01, 8.2000e+00, 9.5098e+01, 2.7756e+02, 9.0282e+04,\n",
       "        2.7792e+02, 0.0000e+00, 0.0000e+00, 3.5300e+01, 1.7567e+02, 2.0455e-01,\n",
       "        1.0000e+00, 5.0000e+00, 6.0000e+00, 1.0000e+00, 0.0000e+00, 8.0000e+00,\n",
       "        2.4000e+01, 5.8000e+00, 5.7808e+01, 2.7716e+02, 9.0303e+04, 2.7760e+02,\n",
       "        0.0000e+00, 0.0000e+00, 1.4700e+01, 4.8655e+01, 5.7620e-01, 1.0000e+00,\n",
       "        6.0000e+00, 6.0000e+00, 1.0000e+00, 0.0000e+00, 1.4000e+01, 4.9600e+01,\n",
       "        5.0000e+00, 7.9488e+01, 2.7727e+02, 9.0312e+04, 2.7765e+02, 0.0000e+00,\n",
       "        0.0000e+00, 2.4300e+01, 3.1495e+01, 1.0082e+00, 1.0000e+00, 7.0000e+00,\n",
       "        6.0000e+00, 1.0000e+00, 0.0000e+00, 1.2000e+01, 3.9600e+01, 2.0400e+01,\n",
       "        7.0238e+01, 2.7676e+02, 9.0271e+04, 2.7734e+02, 0.0000e+00, 0.0000e+00,\n",
       "        1.0200e+01, 1.4726e+01, 1.1610e+00, 1.0000e+00, 8.0000e+00, 6.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 2.6000e+01, 4.9100e+01, 3.9500e+01, 6.3589e+01,\n",
       "        2.7618e+02, 9.0240e+04, 2.7684e+02, 0.0000e+00, 0.0000e+00, 1.1400e+01,\n",
       "        3.6122e+00, 1.0261e+00, 1.0000e+00, 9.0000e+00, 6.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 2.2000e+01, 6.6200e+01, 3.9700e+01, 1.0020e+02, 2.7511e+02,\n",
       "        9.0278e+04, 2.7571e+02, 0.0000e+00, 0.0000e+00, 1.0200e+01, 3.4184e+02,\n",
       "        1.2992e+00, 1.0000e+00, 1.0000e+01, 6.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        1.9000e+01, 4.0800e+01, 5.0000e+01, 8.6811e+01, 2.7502e+02, 9.0294e+04,\n",
       "        2.7586e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00, 3.5157e+02, 1.3317e+00,\n",
       "        1.0000e+00, 1.1000e+01, 6.0000e+00, 1.0000e+00, 0.0000e+00, 1.7000e+01,\n",
       "        9.4000e+00, 3.7500e+01, 7.1780e+01, 2.7509e+02, 9.0255e+04, 2.7579e+02,\n",
       "        0.0000e+00, 0.0000e+00, 1.9000e+00, 7.1282e+00, 1.6932e+00, 1.0000e+00,\n",
       "        1.2000e+01, 6.0000e+00, 1.0000e+00, 0.0000e+00, 1.9000e+01, 8.3000e+00,\n",
       "        3.9400e+01, 5.4050e+01, 2.7521e+02, 9.0218e+04, 2.7605e+02, 0.0000e+00,\n",
       "        0.0000e+00, 4.0000e-01, 3.5431e+02, 1.5219e+00, 1.0000e+00, 1.3000e+01,\n",
       "        6.0000e+00, 1.0000e+00, 0.0000e+00, 2.1000e+01, 9.3000e+00, 3.1500e+01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_trans.__getitem__(0)['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''****************************model prepration*******************************''' \n",
    "# 将网络参数导入网络\n",
    "net = Net(IN_DIM,SEQUENCE_LENGTH,LSTM_IN_DIM,LSTM_HIDDEN_DIM,OUT_DIM,USE_GPU)\n",
    "# print('网络模型准备完毕')\n",
    "\n",
    "# 判断GPU是否可用，如果可用则将net变成可用GPU加速的net\n",
    "if USE_GPU:\n",
    "    net = net.cuda()\n",
    "    # print('本次实验使用GPU加速')\n",
    "else:\n",
    "    pass\n",
    "    # print('本次实验不使用GPU加速')\n",
    "\n",
    "# 使用SGD（随机梯度下降）优化，学习率为0.001，动量为0.9\n",
    "# optimizer = optim.SGD(net.parameters(), lr= LEARNING_RATE, momentum=0.9) \n",
    "# 根据梯度调整参数数值，Adam算法\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# 学习率根据训练的次数进行调整\n",
    "adjust_lr = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                     milestones=[i*10 for i in range(EPOCHES//10)],\n",
    "                                     gamma=0.5)\n",
    "\n",
    "# 定义训练损失函数&测试误差函数\n",
    "# loss_criterion = nn.SmoothL1Loss()\n",
    "loss_criterion = nn.MSELoss()\n",
    "error_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuman\\anaconda3\\envs\\pytorch_v1\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT!: torch.Size([200, 204])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Code-SpatioTemporalAttention-LSTM-main\\modelbase.py:249: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alpha_t = self.softmax(alpha_t)\n",
      "D:\\Code\\Code-SpatioTemporalAttention-LSTM-main\\modelbase.py:272: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  beta_t = self.softmax(beta_t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n",
      "OUT!: torch.Size([200, 204])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-52fc20902547>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0madjust_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-dc0d1fa1248c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#获得网络输出结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0malphas_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Code\\Code-SpatioTemporalAttention-LSTM-main\\modelbase.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_in_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_in_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# on cuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0malpha_t\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_A\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0malpha_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch_v1\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#记录程序开始的时间\n",
    "train_start = time.time()\n",
    "loss_recorder = []\n",
    "\n",
    "min_val_loss = 9999\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "print('starting training... ')\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "\n",
    "    # adjust learning rate\n",
    "    adjust_lr.step()\n",
    "\n",
    "    train_loss_list, alphas_list, betas_list = train(verbose= True)\n",
    "    train_loss = np.mean(train_loss_list)\n",
    "    \n",
    "    loss_recorder.append(train_loss)\n",
    "       \n",
    "    vali_loss = np.mean(vali())\n",
    "\n",
    "    print('epoch = %d, train loss = %.5f, vali loss = %.5f'%(epoch+1,train_loss,vali_loss))\n",
    "    \n",
    "    if min_val_loss > vali_loss**0.5:\n",
    "        min_val_loss = vali_loss**0.5\n",
    "        print(\"Saving...\")\n",
    "        torch.save(net.state_dict(), './models/sta_lstm_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.pt')\n",
    "        \n",
    "        # save the mean alphas and betas to csv if saving the model\n",
    "        alphas = np.mean(np.array(alphas_list), axis=0)\n",
    "        betas = np.mean(np.array(betas_list), axis=0)\n",
    "        np.savetxt('./data/output/A_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.csv', alphas, delimiter=',')\n",
    "        np.savetxt('./data/output/B_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.csv', betas, delimiter=',')\n",
    "        \n",
    "        counter = 0\n",
    "    else: \n",
    "        counter += 1\n",
    "\n",
    "    if counter == patience:\n",
    "        break\n",
    "    \n",
    "print ('training time = {}s'.format(int((time.time() - train_start))))\n",
    "\n",
    "net.load_state_dict(torch.load('./models/sta_lstm_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.pt'))\n",
    "\n",
    "# 记录测试开始的时间\n",
    "test_start = time.time()\n",
    "predictions, test_groundtruth, average_error = test()\n",
    "\n",
    "print(predictions.shape)\n",
    "print(test_groundtruth.shape)\n",
    "\n",
    "print('test time = {}s'.format(int((time.time() - test_start)+1.0)))\n",
    "print('average error = ',  average_error)\n",
    "\n",
    "result = pd.DataFrame(data = {'Q(t+1)':predictions,'Q(t+1)truth':test_groundtruth})\n",
    "result.to_csv('./data/output/out_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def RMSE(v, v_):\n",
    "    '''\n",
    "    Mean squared error.\n",
    "    :param v: np.ndarray or int, ground truth.\n",
    "    :param v_: np.ndarray or int, prediction.\n",
    "    :return: int, RMSE averages on all elements of input.\n",
    "    '''\n",
    "    return np.sqrt(np.mean((v_ - v) ** 2))\n",
    "\n",
    "def MAE(v, v_):\n",
    "    '''\n",
    "    Mean absolute error.\n",
    "    :param v: np.ndarray or int, ground truth.\n",
    "    :param v_: np.ndarray or int, prediction.\n",
    "    :return: int, MAE averages on all elements of input.\n",
    "    '''\n",
    "    return np.mean(np.abs(v_ - v))\n",
    "\n",
    "print(cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon),', Test RMSE,', round(RMSE(test_groundtruth, predictions),4), ', Test MAE,', round(MAE(test_groundtruth, predictions),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "alphas = np.loadtxt('./models/A_'+cols_PM25[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.csv', delimiter=',')\n",
    "alphas = np.transpose(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), dpi=300)\n",
    "im = ax.imshow(alphas)\n",
    "ax.set_xticks(np.arange(SEQUENCE_LENGTH))\n",
    "ax.set_yticks(np.arange(len(cols)))\n",
    "ax.set_xticklabels([\"t-\"+str(i) for i in np.arange(SEQUENCE_LENGTH, 0, -1)])\n",
    "ax.set_yticklabels(cols)\n",
    "# for i in range(len(cols)):\n",
    "#     for j in range(SEQUENCE_LENGTH):\n",
    "#         text = ax.text(j, i, round(alphas[i, j], 3),\n",
    "#                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "ax.set_title(\"Importance of features and timesteps\")\n",
    "\n",
    "# Calculate (height_of_image / width_of_image)\n",
    "im_ratio = alphas.shape[0]/alphas.shape[1]\n",
    "plt.colorbar(im, fraction=0.047*im_ratio, pad=0.01)\n",
    "plt.savefig('./models/A_'+cols_PM25[0].split('_')[0]+'_t'+str(SEQUENCE_LENGTH)+'_'+str(prediction_horizon)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment result:\n",
    "\n",
    "- 060370016_PM2.5_t72_1, Test RMSE, 3.9513 , Test MAE, 2.7456\n",
    "- 060370016_PM2.5_t48_1 Test RMSE, 4.4159 , Test MAE, 2.6177\n",
    "- 060370016_PM2.5_t36_1 , Test RMSE, 4.1832 , Test MAE, 2.6065\n",
    "- 060370016_PM2.5_t12_1 , Test RMSE, 3.9024 , Test MAE, 2.5755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
